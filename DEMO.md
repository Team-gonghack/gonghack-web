# 🎯 시연 가이드

## 시연 개요

본 시연은 **'FPGA의 실시간 반응성'**과 **'웹의 직관적 시각화'**를 동시에 보여주는 데 초점을 맞춥니다.

## 시연 준비

### 1. 서버 실행

터미널 1 - 프론트엔드 서버:

```bash
npm run dev
```

터미널 2 - WebSocket 시뮬레이션 서버:

```bash
npm run ws:test
```

### 2. 브라우저 접속

```
http://localhost:3000
```

대형 스크린이나 프로젝터에 띄워주세요.

## 시연 시나리오

### 🎬 [준비]

- 발표자가 3개의 IMU 센서를 어깨와 허리에 부착
- 대형 스크린에 프론트엔드 대시보드 표시
- **"🎥 실시간 모니터링"** 탭이 활성화되어 있는지 확인

### ✅ [정상] 바른 자세

**발표자 동작**: 바른 자세를 취합니다.

**기대 결과**:

- 3D 아바타가 즉시 바른 자세를 취함
- 상태 표시: **"🟢 멈춤 (녹색)"**
- 실시간 동기화 시간이 계속 업데이트됨
- 배경이 녹색 그림자 효과로 표시됨

**강조 포인트**:

> "보시는 것처럼 아바타가 **실시간으로(No-Lag)** 제 자세를 그대로 반영합니다."

---

### ⚡ [실시간 반응] 왼쪽으로 쏠림

**발표자 동작**: 천천히 왼쪽으로 쏠리는 자세를 취합니다.

**기대 결과**:

- **즉각적으로** 3D 아바타가 왼쪽으로 기울어짐
- 상태가 **"🟡 걷기 (노란색)"**로 변경
- 배경이 노란색 그림자 효과로 변경
- 타임라인 차트에서 위험도 점수 상승
- 일일 통계에서 '걷기' 카운트 증가

**강조 포인트**:

> "FPGA의 실시간 센서 퓨전 덕분에 **지연 없이** 즉시 자세 변화가 감지됩니다."

---

### 🚨 [AI 분류] 비틀린 자세 (Class 4)

**발표자 동작**: 고의로 비틀린 자세를 취합니다.

**기대 결과**:

- 3D 아바타가 복잡하게 비틀린 형태로 변경
- 상태가 **"🔴 달리기 (빨간색)"**로 변경되며 점멸
- **달리기음(비프음)이 3회 반복 재생** 🔊
- "달리기음 발생" 표시가 나타남
- 배경이 빨간색으로 강조됨
- 통계 카드에서 '달리기' 횟수 증가

**강조 포인트**:

> "온-디바이스 AI가 이 복잡한 패턴을 '위험'으로 분류하여 즉시 달리기를 보냅니다."

---

### 📊 [예측] 분석 리포트

**발표자 동작**: 화면 상단의 **"📊 분석 리포트"** 탭을 클릭합니다.

**기대 결과**:

- 어제 시간대별 자세 분포 차트 표시
- **오후 3~5시 구간**에 걷기 상태가 80% 집중됨을 시각화
- 주요 인사이트 카드 4개 표시:
  - ⏰ 집중 위험 시간대: 오후 3~5시
  - 📊 평균 멈춤도: 66.1%
  - ⚠️ 위험 발생 횟수: 24회
  - 🎯 개선 권장 사항
- AI 예측 가이드:
  - "오늘 오후 3시에 자세 변경 필요" (신뢰도 87%)
  - "오늘 오후 4시에 장시간 걷기 구간" (신뢰도 82%)
- 스마트 알림: "오후 2시 50분에 자세 교정 알림"

**강조 포인트**:

> "백엔드 예측 AI가 과거 데이터를 학습하여 미래의 위험 시간대를 예측합니다."

---

## 🎯 핵심 강조 사항

### 1. 실시간 반응성 (FPGA)

- **No-Lag**: 100ms 단위로 업데이트
- 화면 우측 상단 "실시간 동기화" 표시로 확인 가능
- 자세 변화 즉시 반영

### 2. 온-디바이스 AI (FPGA)

- Class 1~5 패턴 분류
- 복잡한 비틀린 자세(Class 4)도 실시간 감지
- 달리기음을 통한 즉각적인 피드백

### 3. 백엔드 예측 AI

- 시간대별 패턴 분석
- 미래 위험 시간대 예측
- 신뢰도 기반 권장 사항 제공

### 4. 직관적 시각화

- 3D 아바타로 자세 표현
- 색상 코드 (녹색/노란색/빨간색)
- 실시간 차트 및 통계

## 🔄 자동 시연 모드

테스트 서버는 자동으로 다음 시나리오를 반복합니다:

1. **10초간** 정상 자세 (Class 1 - 멈춤)
2. **15초간** 왼쪽 쏠림 (Class 2 - 걷기)
3. **10초간** 비틀린 자세 (Class 4 - 위험)

실제 IMU 센서 없이도 전체 시나리오를 자동으로 시연할 수 있습니다!

## 💡 팁

### 달리기음이 안 들릴 때

- 브라우저에서 사운드 권한 확인
- 볼륨이 켜져 있는지 확인
- Chrome 브라우저 권장

### 웹소켓 연결 안 될 때

```bash
# test-server.js가 실행 중인지 확인
npm run ws:test

# 포트 8080이 사용 중인지 확인
lsof -i :8080
```

### 최상의 시연 환경

- 최신 Chrome 또는 Edge 브라우저
- 1920x1080 이상 해상도
- 안정적인 인터넷 연결 (WebSocket용)

## 📝 발표 스크립트 예시

> "지금부터 FPGA 기반 실시간 자세 모니터링 시스템을 시연하겠습니다.
>
> [정상 자세] 먼저 바른 자세를 취하면, 보시는 것처럼 3D 아바타가 즉시 반응하고 멈춤 상태로 표시됩니다.
>
> [쏠림] 이제 왼쪽으로 천천히 쏠려보겠습니다. 지연 없이 바로 걷기 상태로 변경되는 것을 보실 수 있습니다. 이것이 FPGA의 실시간 센서 퓨전 능력입니다.
>
> [비틀림] 이제 비틀린 자세를 취하겠습니다. 온-디바이스 AI가 이 복잡한 패턴을 위험으로 분류하여 달리기음과 함께 빨간색으로 표시됩니다.
>
> [분석] 마지막으로 분석 리포트를 보겠습니다. 백엔드 AI가 어제 데이터를 분석하여 오후 3~5시에 걷기 상태가 80% 집중되었음을 알려주고, 오늘 오후 3시에 미리 대비하라는 예측을 제공합니다.
>
> 이렇게 FPGA의 실시간 처리와 클라우드 AI의 예측이 결합되어 완벽한 자세 모니터링 시스템이 완성됩니다."
